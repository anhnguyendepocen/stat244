\documentclass{tufte-book}

\usepackage{amsmath, amsthm}
\usepackage{graphicx}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
\graphicspath{{graphics/}}

\title{STATS 244 \\ Homework 1}
\author{Joe Seidel}
\date{\today}

\usepackage{booktabs}
\usepackage{units}
\usepackage{fancyvrb}
\fvset{fontsize=\normalsize}
\usepackage{multicol}
\usepackage{lipsum}
\usepackage{pdfpages}
\usepackage{tikz}
\usepackage{wasysym}

\newcommand{\doccmd}[1]{\texttt{\textbackslash#1}}% command name -- adds backslash automatically
\newcommand{\docopt}[1]{\ensuremath{\langle}\textrm{\textit{#1}}\ensuremath{\rangle}}% optional command argument
\newcommand{\docarg}[1]{\textrm{\textit{#1}}}% (required) command argument
\newenvironment{docspec}{\begin{quote}\noindent}{\end{quote}}% command specification environment
\newcommand{\docenv}[1]{\textsf{#1}}% environment name
\newcommand{\docpkg}[1]{\texttt{#1}}% package name
\newcommand{\doccls}[1]{\texttt{#1}}% document class name
\newcommand{\docclsopt}[1]{\texttt{#1}}% document class option name
\DeclareMathOperator{\proj}{proj}
\newcommand{\vct}{\mathbf}


\newcommand{\dprod}[2]{\langle #1, #2 \rangle}

\newtheoremstyle{mytheoremstyle} % name
	{\topsep}		% Space above
	{\topsep}		% Space below
	{\itshape}		% Body font
	{}			% Indent amount
	{\bfseries}	% Theorem head font
	{\textnormal{:}}	% Punctuation after theorem head
	{.5em}		% Space after theorem head
	{}			%Theorem headspec
\theoremstyle{mytheoremstyle}
\newtheorem*{thm}{Thm.}

\newtheoremstyle{mylemstyle} % name
	{\topsep}		% Space above
	{\topsep}		% Space below
	{\itshape}		% Body font
	{}			% Indent amount
	{\bfseries}	% Theorem head font
	{\textnormal{:}}	% Punctuation after theorem head
	{.5em}		% Space after theorem head
	{}			%Theorem headspec
\theoremstyle{mylemstyle}
\newtheorem*{lem}{Lem.}


\newtheoremstyle{mydefstyle} % name
	{\topsep}		% Space above
	{\topsep}		% Space below
	{\normalfont}	% Body font
	{}			% Indent amount
	{\bfseries}	% Theorem head font
	{\textnormal{:}}	% Punctuation after theorem head
	{.5em}		% Space after theorem head
	{}			%Theorem headspec
\theoremstyle{mydefstyle}
\newtheorem*{mydef}{Def.}
\newtheorem*{ex}{E.g.}

\begin{document}

\maketitle
\pagenumbering{gobble}
\newpage
\pagenumbering{arabic}


\subsection{Rice Chapter 1, 20}
A deck of 52 cards has been shuffled thoroughly. What is the probability that the four aces are next to each other?

Let $A$ be the event that 4 aces are next to each other.  Consider 4 aces as being one card, then there are $(48!4!)$ ways to shuffle the deck with the four aces together.   Since the 4 aces can be anywhere in the deck, there are $49$ locations they can appear in the deck.  Thus there are $\frac{(49)48!4!}{52!}$
\[ \frac{49!4!}{52!} = \frac{4!}{(52)(51)(50)} = \frac{1}{5525} \]


\subsection{Rice Chapter 1, 60}
A factory runs three shifts.  In a given day, $1\%$ of items produced by the first shift are defective, $2\%$ of the second shit's items are defective, and $5\%$ of the third shift's items are defective.  If the shifts all have the same productivity, what percentage of items produced in a day are defective?  If an item is defective, what is the probability that it was produced by the third shift?

\newthought{Suppose WLOG}, the factory produces 300 items a day.  Since all shifts have the same productivity, each shift manufacturs 100 items.   Then the percentage of defective item produced per day is $\frac{8}{300} \approx 2.7\%$.  Conditional on a defective item being chose, the probability that it was produced by the third shift is $P(B \ | \  D)=\frac{\frac{.05}{3}}{\frac{.08}{3}} = \frac{5}{7}$ where D is a defective item.


\subsection{Rice Chapter 1, 72}
Suppose that $n$ components are connected in series.  For each unit, there is a backup unit, and the system fails if and only if both a unit and its backup fail.  Assuming the all the units are independent and fail with probability $p$, what is the probability that the system works?  For $n=10$ and $p=.05$.

\newthought{For any given} component the probability of failure is
\[ p^2=.05^2=.0025 \]
Let $F$ be probability of failure. Following example F, we'll find the probability of the compliment of this event, $P(F^c)$ or probability that all the components work.
\begin{align}
P(F) &= 1 - P(F^c) \\
&= 1 - (1-p)^n \\
&= 1 - (1-.0025)^{10} \\
&= 1 - (.975) \\
&= .025
\end{align}
The probability of failure in example F was $.40$ so this is a considerable improvement.


\subsection{Rice Chapter 1, 78}
This problem introduces some aspects of a simple genetic model.  Assume that genes in an organism occur in pairs and that each member of the pair can be either of the types $a$ or $A$.  The possible genotypes of an organism are then $AA$, $Aa$ and $aa$ ($Aa$ and $aA$ are equivalent).  When two organisms mate, each independently contributes one of its two genese; either one of the pair is transmitted with probability $.5$.
\begin{enumerate}
\item Suppose that the genotypes of the parents are $AA$ and $Aa$. Find the possible genotypes of their offspring and the corresponding probabilities.

\newthought{Consider the table}\\
\begin{tabular}{ r|c|c| }
\multicolumn{1}{r}{}
 &  \multicolumn{1}{c}{A}
 & \multicolumn{1}{c}{A} \\
\cline{2-3}
A & AA & AA \\
\cline{2-3}
a & Aa & Aa \\
\cline{2-3}
\end{tabular}

The possible genotypes are $\{AA, Aa \}$, both with $.5$ probability.

\item Suppose that the probabilies of the genotypes $AA$, $Aa$ and $aa$ are $p$, $2q$, and $r$, respectively, in the first generation.  Find the probabilities in the second and third generations and show that these are the same.  This result is called the Hardy-Weinberg Law.

\newthought{The probabilities tables} for each genome type given parent types are as follows.

\begin{tabular}{ r|c|c|c| }
\multicolumn{1}{r}{P(AA)}\\
\multicolumn{1}{r}{}
 & \multicolumn{1}{c}{AA}
 & \multicolumn{1}{c}{Aa}
 & \multicolumn{1}{c}{aa} \\
\cline{2-4}
AA & 1 & .5 & 0 \\
\cline{2-4}
Aa & .5 & .25 & 0 \\
\cline{2-4}
aa & 0 & 0 & 0 \\
\cline{2-4}
\end{tabular}

\begin{tabular}{ r|c|c|c| }
\multicolumn{1}{r}{P(Aa)}\\
\multicolumn{1}{r}{}
 & \multicolumn{1}{c}{AA}
 & \multicolumn{1}{c}{Aa}
 & \multicolumn{1}{c}{aa} \\
\cline{2-4}
AA & 0 & .5 & 1 \\
\cline{2-4}
Aa & .5 & .5 & .5 \\
\cline{2-4}
aa & 1 & .25 & 0 \\
\cline{2-4}
\end{tabular}

\begin{tabular}{ r|c|c|c| }
\multicolumn{1}{r}{P(aa)}\\
\multicolumn{1}{r}{}
 & \multicolumn{1}{c}{AA}
 & \multicolumn{1}{c}{Aa}
 & \multicolumn{1}{c}{aa} \\
\cline{2-4}
AA & 0 & 0 & 0 \\
\cline{2-4}
Aa & 0 & .25 & .5 \\
\cline{2-4}
aa & 0 & .5 & 1 \\
\cline{2-4}
\end{tabular}

$P_g(x)$ is the probability of a genotype for generation $g$.

\begin{align*}
P_2(AA) &= P_2(AA \mid AA,AA)P_1(AA,AA) \\
&+ 2(P_2(AA\mid AA, Aa)P_1(AA,Aa))\\
&+ P_2(AA \mid Aa, Aa)P_1(Aa,Aa))\\
&= (1)(p^2) + 2(.5)(2pq) + (.25)(4q^2)\\
&= p^2 + 2pq + q^2\\
&= (p+q)^2
\end{align*}

\begin{align*}
P_2(Aa) &= P_2(Aa \mid Aa,Aa)P_1(Aa,Aa)\\
&+ 2(P_2(Aa\mid AA, Aa)P_1(AA, Aa))\\
&+ 2(P_2(Aa\mid Aa, aa)P_1(Aa,aa))\\
&+ 2(P_2(Aa\mid AA,aa)P_1(AA,aa))\\
&= (.5)(4q^2) + 2(.5)(2pq) \\
&+ 2(.25)(2qr) + 2(1)(pr)\\
&= 2q^2+2pq+2pqr_2pr \\
&=2(q+p)(q+r)
\end{align*}

\begin{align*}
P_2(aa) &= P_2(aa \mid Aa,Aa)P(Aa,Aa)\\
&+ 2(P_2(aa\mid Aa,aa)P_1(Aa,aa)\\
&+ P_2(aa\mid aa,aa)P_1(aa,aa)\\
&= (.25)(4q^2) + 2(.5)(2pr) + (1)(r^2)\\
&= q^2 + 2qr + r^2\\
&= (q+r)^2
\end{align*}

\begin{proof} It has been shown above that $P_2(AA)=(p+q)^2$, $P_2(Aa)=2(q+p)(q+r)$ and $P_2(aa)=(q+r)^2$.  To find the Hardy-Weinberg Law result,we must show that $P_2(AA)=P_3(AA)$, $P_2(Aa)=P_3(Aa)$ and $P_2(aa)=P_3(aa)$.

First, it will be important to note that the three probabilities for a given generation's offspring will sum to 1.  Ie...
\[ (q+p)^2 + 2(q+p)(q+r) + (q+r)^2 = 1 \]

Using the method to determine probabilities for generation 2 we can determine generation 3.

\begin{align*}
P_3(AA) &= 1(p+q)^4 + 2(.5)(p+q)^2 \\
&+ 2(q+p)(q+r) + (.25)4(p+q)(q+r)^2 \\
&= (p+q)^4 + 2(p+q)^3(q+r)+(p+q)^2(q+r)^2 \\
&= (p+q)^2[(p+q)^2 + 2(p+q)(q+r) + (q+r)^2]\\
&= (p+q)^2
\end{align*}

\begin{align*}
P_3(Aa) &= (.25)(4)(q+p)^2(q+r)^2 + 2(.5)2(p+q)(q+r)(p+q)^2\\
&= 2(.5)2(p+q)(q+r)(q+r)^2 + 2(p+q)^2(q+r)^2\\
&= 2(p+q)^2(q+r)^2 + 2(p+q)^3(q+r)\\
&+ 2(p+q)(q+r)^3 + 2(p+q)^2(q+r)^2\\
&= 2(q+p)(q+r)[(q+p)(q+r) + (p+q)^2\\
&+ (q+r)^2 (q+r)(q+r)]\\
&= 2(q+p)(q+r)[(p+q)^2 + 2(q+p)(q+r) +(q+r)^2]\\
&= 2(q+p)(q+r)
\end{align*}

\begin{align*}
P_3(aa) &= .25(4)(q+p)^2(q+r)^2\\
&+ 2(.5)(q+r)^22(q+p)(q+r) + 1(q+r)^2\\
&= (q+p)^2(q+r)^2 = 2(q+r)^3(q+p) + (q+r)^4\\
&= (q+r)^2[(q+p)^2 + 2(q+r)(q+p) + (q+r)^2]\\
&= (q+r)^2
\end{align*}

\end{proof}

\end{enumerate}


\subsection{Rice Chapter 2, 8}
Show that the binomial probabilies sum to 1.

\begin{proof}The binomial distribution $(n,\theta)$ is given as
\[ b(x;n,\theta) = \binom{n}{x}\theta(1-\theta)^{n-x}  \text{ for } x=1,2,...,n\]

Since $(a+b)^n=\sum_{k=0}^n\binom{n}{k}a^kb^{n-k}$

\begin{align*}
\sum b(x;n,\theta) &= \sum_{x=0}^{n}\binom{n}{x}\theta(1-\theta)^{n-x}\\
&= (\theta+1-\theta )^n\\
&= 1
\end{align*}
\end{proof}


\subsection{Rice Chapter 2, 28}

Let $p_0, p_1,...,p_n$ denote the probability mass function of the binomial distribution with parameters $n$ and $p$.  Let $q=1-p$.  Show that the binomial probabilies can be compitered recursively by $p_0=q^n$ and
\[ p_k = \frac{(n-k+1)p}{kq}p_{k-1} \text{, } k=1,2,...,n \]
Use this relation to find $P(X\leq4)$ for $n=9000$ and $p=.0005$.

\begin{proof}The binomial mass function for the parameters $n$ and $p$ and $q=1-p$ for $P(X=0)$ is

\begin{align*}
p_0 &= \binom{n}{0}p^0(1-p)^{n-0}\\
&= \frac{n!}{0!n!}p^0(q)^n\\
&= q^n
\end{align*}

Now consider \marginnote{Binomial identity: $\binom{n}{k} = \frac{n+1-k}{k}\binom{n}{k-1}$}
\begin{align*}
p_1 &= \binom{n}{1}p^1q^{n-1}\\
&= \frac{n+1-1}{1}\binom{n}{1-1}p^1q^{n-1}\\
&= n\binom{n}{0}pq^{n-1}\\
&= npq^{n-1}
\end{align*}

Taking the ratio of $p_1$ and $p_0$

\begin{align*}
\frac{p_1}{p_0} &= \frac{npq^{n-1}}{q^n}\\
&= \frac{np}{q}
\end{align*}

Then
\[ p_1 = \frac{np}{q}p_0 \]

More generally, since
\begin{align*}
p_k &= \binom{n}{k}p^kq^{n-k}\\
&= \frac{n+1-k}{k}\binom{n}{k-1}p^kq^{n-k}\\
\end{align*}
and
\begin{align*}
p_{k-1} &= \binom{n}{k-1}p^{k-1}q^{n-(k-1)}\\
\end{align*}
then
\begin{align*}
\frac{p_k}{p_{k-1}} &= \frac{\frac{n+1-k}{k}\binom{n}{k-1}p^kq^{n-k}}{\binom{n}{k-1}p^{k-1}q^{n-(k-1)}}\\
&= \frac{(n+1-k)}{k}pq^{-1}\\
&= \frac{(n+1-k)p}{kq}\\
\end{align*}

Therefore
\[p_k = \frac{(n+1-k)p}{kq}p_{k-1} \]
\end{proof}

\newthought{Using this relation} we can find $P(X\leq4)$ for $n=9000$ and $p=.0005$.
\begin{align*}
P(X\leq4) &= \sum_{k=0}^4p_k\\
&= (.011)+(.05)+(.11)+(.16)+(.18)\\
&= .511
\end{align*}

\subsection{Question 7}
In heads up Texas hold 'em (two players, each dealt two cards), find the probability that neither is dealt a pair (two cards of the same rank).  If there are three players, what is the probability that none have a pair?

\newthought{Let} $A$ be the event that the first player gets a pair and let $B$ be the event that the second player gets a pair.  The probability that no player gets a pair is

\[1-(P(A) + P(B) - P(A\cap B))\]
\[1-2(.0588) - (.0048)) = .8822\]

\newthought{Now let} $C$ be the probability that the third player gets a pair.  We can calcute the probability that none of the players get a pair using

\begin{align*}
1 - P(A\cup B\cup C) &= 1 - (P(A) + P(B) + P(C)\\
&- P(A\cap B) - P(C\cap A) - P(B \cap C) \\
&+ P(A\cap B\cap C))
\end{align*}

Where $P(A) = P(B) = P(C) = .0588$ and $P(A\cap C) \approx P(C\cap A) \approx P(B \cap C)\approx .0048$.

\begin{align*}
P(A\cap B\cap C) &= P(A)P(B\mid A)P(C\mid A,B)\\
&=(.0588)(.0816)(.0178)\\
\end{align*}

The probability that no player has a pair is $.838$.


\subsection{Question 8}
For a Poisson process $N(,)$ with parameter $\lambda$, find the probabilities of the following events:

\begin{enumerate}
\item $N((1,5])>1$
For a Poisson process the probability of k success over an interval of length $t$ is
\[p(k) = \frac{\lambda t^ke^{-\lambda t}}{k!} \]

Since
\[ P(N((1,5])>1) = 1 - P(N(1,5]=0)) - P(N(1,5]=1)) \]
Compute and take the sum of the probabilities of each number of outcomes.
\begin{align*}
P(N((1,5])>1) &= 1 - \frac{\lambda(4)^0e^{-\lambda(4)}}{0!} - \frac{\lambda(4)^{1}e^{-\lambda(4)}}{1!}\\
&= 1 - e^{-4\lambda} - 4\lambda e^{-4\lambda}\\
&= 1- e^{-4\lambda}(1- 4\lambda)
\end{align*}

\item N((0,1]) = N((0,2])

Take $P(N(0,1]=k) \cap P(N(0,2]=k))$
\[\frac{\lambda^ke^{-\lambda}}{k!} * \frac{\lambda 2^ke^{-\lambda 2}}{k!} =
\frac{2\lambda^{2k}e^{-3\lambda}}{(k!)^2} \]

\item N((1,2]) + N((3,4]) = 6

Let $I$ be the index set of all pairs $x,y$ for which $x+y=6$ where $x,y \geq 0$.  Denote $A=N(1,2])$ and $B=N(2,3])$  Take
\[\sum_{i\in I}P(A=x_i)P(B=y_i) \text{ for } x,y \in I.\]

Which computes to $\frac{26.5}{180}(\lambda^{2k}e^{-2\lambda})$.

\item N((0,1]) = N((1,2])+m for $m$ a nonnegative integer. Express you answer as an infinite series and then write your result in terms of a Bessel function (look it up).  This result in terms of Bessel functions can be used to, for example, give a simple accurate approximation to this probability when $m$ is large.

\newthought{Proved some} integer $m$.  Find $P(N(0,1])=k+m \cap N(1,2]=k)$, denote these $P(A)$ and $P(B)$, respectively.

\[ p(A) = \frac{\lambda t^{(k+m)}e^{-\lambda t}}{(k+m)!} \]
\[ p(B) = p(k) = \frac{\lambda t^ke^{-\lambda t}}{k!} \]

Multiplying the two yields
\[ \frac{1}{k!(k+m)!}\lambda^{(2k+m)}e^{-2\lambda}. \]

As $m$ gets larger the probability of $m$ outcomes will get closer and closer to $0$.
\end{enumerate}
\end{document}
\grid
